<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RunCatcher - Hybrid</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>RunCatcher</h1>
            <p>Face detection + manual capture with motion auto-capture</p>
        </header>

        <div class="main-content">
            <div class="video-section">
                <div class="video-container">
                    <video id="video" autoplay muted playsinline></video>
                    <canvas id="canvas" width="640" height="480"></canvas>
                </div>
                <div class="controls">
                    <button id="startBtn" class="btn btn-primary">Start</button>
                    <button id="stopBtn" class="btn btn-secondary" disabled>Stop</button>
                    <button id="captureBtn" class="btn btn-primary" disabled>Capture</button>
                    <button id="motionBtn" class="btn btn-secondary" disabled>Toggle Motion</button>
                    <div class="status"><span id="status">Ready</span></div>
                    <div class="motion-info">
                        <div>Motion: <span id="motionSpeed">0</span> px/s</div>
                        <div>Auto-Capture: <span id="motionStatus">Off</span></div>
                    </div>
                </div>
            </div>

            <div class="runners-section">
                <h2>Captures</h2>
                <div id="runnersList" class="runners-list">
                    <p class="no-runners">No captures yet</p>
                </div>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script>
    class RunCatcherHybrid {
        constructor() {
            this.video = document.getElementById('video');
            this.canvas = document.getElementById('canvas');
            this.ctx = this.canvas.getContext('2d');
            this.startBtn = document.getElementById('startBtn');
            this.stopBtn = document.getElementById('stopBtn');
            this.captureBtn = document.getElementById('captureBtn');
            this.motionBtn = document.getElementById('motionBtn');
            this.status = document.getElementById('status');
            this.motionStatus = document.getElementById('motionStatus');
            this.motionSpeed = document.getElementById('motionSpeed');
            this.runnersList = document.getElementById('runnersList');

            this.isRunning = false;
            this.faceApiLoaded = false;
            this.motionDetection = false;
            this.previousFaces = [];
            this.photoCount = 0;
            this.motionThreshold = 800; // px/s - VERY high = barely sensitive
            this.captureCooldown = 10000; // ms - 10 second cooldown
            this.lastCaptureTime = 0;
            this.currentMotionSpeed = 0;
            this.highMotionStartTime = 0; // Track when high motion started

            this.init();
        }

        async init() {
            this.bind();
            await this.loadModels();
            await this.initCamera();
        }

        bind() {
            this.startBtn.addEventListener('click', () => this.start());
            this.stopBtn.addEventListener('click', () => this.stop());
            this.captureBtn.addEventListener('click', () => this.captureManual());
            this.motionBtn.addEventListener('click', () => this.toggleMotion());
        }

        async loadModels() {
            try {
                this.status.textContent = 'Loading face detection models...';
                
                // Try multiple CDN sources with timeout
                const modelUrls = [
                    'https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights',
                    'https://unpkg.com/face-api.js@0.22.2/weights',
                    'https://cdnjs.cloudflare.com/ajax/libs/face-api.js/0.22.2/weights',
                    'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights'
                ];
                
                let modelsLoaded = false;
                let lastError = null;
                
                for (const baseUrl of modelUrls) {
                    try {
                        console.log(`Trying to load models from: ${baseUrl}`);
                        
                        // Add timeout to prevent hanging
                        const loadPromise = Promise.all([
                            faceapi.nets.tinyFaceDetector.loadFromUri(baseUrl),
                            faceapi.nets.faceLandmark68Net.loadFromUri(baseUrl)
                        ]);
                        
                        const timeoutPromise = new Promise((_, reject) => 
                            setTimeout(() => reject(new Error('Timeout')), 10000)
                        );
                        
                        await Promise.race([loadPromise, timeoutPromise]);
                        
                        modelsLoaded = true;
                        console.log('Models loaded successfully from:', baseUrl);
                        break;
                        
                    } catch (error) {
                        console.warn(`Failed to load from ${baseUrl}:`, error.message);
                        lastError = error;
                        continue;
                    }
                }
                
                if (modelsLoaded) {
                    this.faceApiLoaded = true;
                    this.status.textContent = 'Models loaded. Ready to start detection.';
                    this.startBtn.disabled = false;
                } else {
                    // Try fallback with just basic model
                    this.status.textContent = 'Trying fallback model...';
                    try {
                        await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights');
                        this.faceApiLoaded = true;
                        this.status.textContent = 'Basic model loaded. Ready to start detection.';
                        this.startBtn.disabled = false;
                    } catch (fallbackError) {
                        throw new Error('All model sources failed');
                    }
                }
                
            } catch (error) {
                console.error('Model loading failed:', error);
                this.status.textContent = 'Face detection unavailable. Manual capture still works.';
                this.startBtn.disabled = false;
                this.captureBtn.disabled = false;
                this.motionBtn.disabled = true;
                
                // Show helpful message
                this.showModelError();
            }
        }
        
        showModelError() {
            const errorDiv = document.createElement('div');
            errorDiv.style.cssText = `
                background: #f8d7da; 
                border: 1px solid #f5c6cb; 
                color: #721c24; 
                padding: 15px; 
                margin: 10px 0; 
                border-radius: 5px;
                font-size: 14px;
            `;
            errorDiv.innerHTML = `
                <strong>Face Detection Models Failed to Load</strong><br>
                This usually happens due to:<br>
                • Internet connection issues<br>
                • CDN blocking or rate limiting<br>
                • Browser security restrictions<br><br>
                <strong>Solutions:</strong><br>
                • Check your internet connection<br>
                • Try refreshing the page<br>
                • Disable ad blockers temporarily<br>
                • Try a different browser<br><br>
                <em>Manual capture still works without face detection!</em>
            `;
            document.querySelector('.video-section').appendChild(errorDiv);
        }

        async initCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: { ideal: 640 }, height: { ideal: 480 }, facingMode: 'user' }
                });
                this.video.srcObject = stream;
                this.video.onloadedmetadata = () => {
                    this.canvas.width = this.video.videoWidth;
                    this.canvas.height = this.video.videoHeight;
                };
            } catch (e) {
                this.status.textContent = 'Camera error';
            }
        }

        start() {
            this.isRunning = true;
            this.startBtn.disabled = true;
            this.stopBtn.disabled = false;
            this.captureBtn.disabled = false;
            this.motionBtn.disabled = !this.faceApiLoaded;
            this.status.textContent = 'Detecting...';
            this.loop();
        }

        stop() {
            this.isRunning = false;
            this.startBtn.disabled = false;
            this.stopBtn.disabled = true;
            this.motionBtn.disabled = true;
            this.status.textContent = 'Stopped';
            this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
            this.motionStatus.textContent = 'Off';
            this.motionSpeed.textContent = '0';
        }

        toggleMotion() {
            this.motionDetection = !this.motionDetection;
            this.motionStatus.textContent = this.motionDetection ? 'On' : 'Off';
            this.motionBtn.textContent = this.motionDetection ? 'Stop Motion' : 'Toggle Motion';
        }

        async loop() {
            if (!this.isRunning) return;
            try {
                let detections = [];
                if (this.faceApiLoaded) {
                    detections = await faceapi
                        .detectAllFaces(this.video, new faceapi.TinyFaceDetectorOptions())
                        .withFaceLandmarks();
                }
                this.drawBoxes(detections);
                if (this.motionDetection && detections.length) {
                    this.updateMotion(detections);
                }
            } catch (e) {}
            requestAnimationFrame(() => this.loop());
        }

        drawBoxes(detections) {
            this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
            detections.forEach((d, i) => {
                const b = d.detection.box;
                const running = this.motionDetection && this.currentMotionSpeed > this.motionThreshold;
                
                // Draw main bounding box
                this.ctx.strokeStyle = running ? '#e74c3c' : '#c0392b';
                this.ctx.lineWidth = 3;
                this.ctx.strokeRect(b.x, b.y, b.width, b.height);
                
                // Draw corner squares
                const cornerSize = 20;
                this.ctx.fillStyle = running ? '#e74c3c' : '#c0392b';
                
                // Top-left corner
                this.ctx.fillRect(b.x - 2, b.y - 2, cornerSize, 4);
                this.ctx.fillRect(b.x - 2, b.y - 2, 4, cornerSize);
                
                // Top-right corner
                this.ctx.fillRect(b.x + b.width - cornerSize + 2, b.y - 2, cornerSize, 4);
                this.ctx.fillRect(b.x + b.width - 2, b.y - 2, 4, cornerSize);
                
                // Bottom-left corner
                this.ctx.fillRect(b.x - 2, b.y + b.height - cornerSize + 2, cornerSize, 4);
                this.ctx.fillRect(b.x - 2, b.y + b.height - 2, 4, cornerSize);
                
                // Bottom-right corner
                this.ctx.fillRect(b.x + b.width - cornerSize + 2, b.y + b.height - 2, cornerSize, 4);
                this.ctx.fillRect(b.x + b.width - 2, b.y + b.height - cornerSize + 2, 4, cornerSize);
                
                // Draw label
                this.ctx.fillStyle = running ? '#e74c3c' : '#c0392b';
                this.ctx.font = '16px Arial';
                this.ctx.fillText(running ? 'RUNNING!' : `Face ${i+1}`, b.x, b.y - 10);
            });
        }

        updateMotion(dets) {
            if (this.previousFaces.length === 0) {
                this.previousFaces = dets.map(x => x.detection.box);
                return;
            }
            const now = dets.map(x => x.detection.box);
            
            // Calculate motion speed with smoothing
            const speeds = now.map(b => {
                let best = Infinity;
                this.previousFaces.forEach(pb => {
                    const d = this.dist(this.center(b), this.center(pb));
                    if (d < best) best = d;
                });
                return best * 60; // approx px/s from per-frame delta at ~60fps
            });
            
            // HEAVY smoothing to reduce noise - much less sensitive
            const avgSpeed = speeds.length ? (speeds.reduce((a,b)=>a+b,0)/speeds.length) : 0;
            this.currentMotionSpeed = this.currentMotionSpeed * 0.9 + avgSpeed * 0.1; // HEAVY smoothing
            
            this.motionSpeed.textContent = this.currentMotionSpeed.toFixed(2);
            this.previousFaces = now;

            // Only auto-capture for sustained high motion (MUCH less sensitive)
            if (this.currentMotionSpeed > this.motionThreshold) {
                const now = Date.now();
                if (this.highMotionStartTime === 0) {
                    this.highMotionStartTime = now; // Start timing high motion
                }
                // Require 2 seconds of sustained high motion before capturing
                if (now - this.highMotionStartTime > 2000) {
                    this.captureAuto();
                    this.highMotionStartTime = 0; // Reset
                }
            } else {
                this.highMotionStartTime = 0; // Reset if motion drops
            }
        }

        center(b){ return { x: b.x + b.width/2, y: b.y + b.height/2 }; }
        dist(a,b){ return Math.hypot(a.x - b.x, a.y - b.y); }
        
        drawSquaresOnCanvas(ctx, width, height, label) {
            // Draw corner squares on the captured photo
            const cornerSize = 30;
            const lineWidth = 4;
            const isAuto = label === 'Auto';
            
            // Set color based on capture type
            ctx.strokeStyle = isAuto ? '#e74c3c' : '#c0392b';
            ctx.fillStyle = isAuto ? '#e74c3c' : '#c0392b';
            ctx.lineWidth = lineWidth;
            
            // Top-left corner
            ctx.fillRect(10, 10, cornerSize, lineWidth);
            ctx.fillRect(10, 10, lineWidth, cornerSize);
            
            // Top-right corner
            ctx.fillRect(width - cornerSize - 10, 10, cornerSize, lineWidth);
            ctx.fillRect(width - lineWidth - 10, 10, lineWidth, cornerSize);
            
            // Bottom-left corner
            ctx.fillRect(10, height - cornerSize - 10, cornerSize, lineWidth);
            ctx.fillRect(10, height - lineWidth - 10, lineWidth, cornerSize);
            
            // Bottom-right corner
            ctx.fillRect(width - cornerSize - 10, height - cornerSize - 10, cornerSize, lineWidth);
            ctx.fillRect(width - lineWidth - 10, height - lineWidth - 10, lineWidth, cornerSize);
            
            // Add capture info text
            ctx.fillStyle = isAuto ? '#e74c3c' : '#c0392b';
            ctx.font = 'bold 24px Arial';
            ctx.fillText(`${label} Capture`, 20, 40);
            ctx.font = '18px Arial';
            ctx.fillText(`Motion: ${this.currentMotionSpeed.toFixed(2)} px/s`, 20, 65);
            ctx.fillText(new Date().toLocaleTimeString(), 20, height - 20);
        }

        captureManual(){ this.capture('Manual'); }
        captureAuto(){
            const now = Date.now();
            if (now - this.lastCaptureTime < this.captureCooldown) {
                console.log('Auto-capture skipped (cooldown)');
                return;
            }
            this.lastCaptureTime = now;
            this.capture('Auto');
            console.log('Auto-captured due to running motion!');
        }

        capture(label){
            this.photoCount++;
            const c = document.createElement('canvas');
            const x = c.getContext('2d');
            c.width = this.video.videoWidth; c.height = this.video.videoHeight;
            x.drawImage(this.video, 0, 0, c.width, c.height);
            
            // Add square corner markers to the captured photo
            this.drawSquaresOnCanvas(x, c.width, c.height, label);
            
            const url = c.toDataURL('image/jpeg', 0.85);
            const item = document.createElement('div');
            item.className = 'runner-item';
            item.innerHTML = `
                <div class="runner-number">${label} #${this.photoCount}</div>
                <img src="${url}" class="runner-image" alt="Capture ${this.photoCount}">
                <div class="runner-info">
                    <div>Type: ${label}</div>
                    <div>Motion: ${this.currentMotionSpeed.toFixed(2)} px/s</div>
                    <div>Time: ${new Date().toLocaleTimeString()}</div>
                </div>
            `;
            const empty = this.runnersList.querySelector('.no-runners');
            if (empty) empty.remove();
            this.runnersList.insertBefore(item, this.runnersList.firstChild);
            
            // Show capture notification
            if (label === 'Auto') {
                this.status.textContent = `🏃‍♂️ AUTO-CAPTURED! Motion: ${this.currentMotionSpeed.toFixed(2)} px/s`;
                // Flash the motion status
                this.motionStatus.style.color = '#e74c3c';
                this.motionStatus.style.fontWeight = 'bold';
                setTimeout(() => {
                    this.motionStatus.style.color = '';
                    this.motionStatus.style.fontWeight = '';
                }, 2000);
            } else {
                this.status.textContent = `📸 ${label} captured #${this.photoCount}`;
            }
        }
    }

    document.addEventListener('DOMContentLoaded', () => new RunCatcherHybrid());
    </script>
</body>
</html>
